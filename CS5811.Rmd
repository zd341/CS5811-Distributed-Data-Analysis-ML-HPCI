---
title: "London_Smartmeter"
author: 'Group 7'
date: "25/02/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

**TABLE OF CONTENTS**  
[Importing and Inspecting datasets](#S1)


```{r Loading Packages}
#Loading Packages
if (require(tidyverse)== FALSE) {
	install.packages("tidyverse")
} else {
	library(tidyverse)
  
}
```
>note:- Please feel free to add the packages that you used for individual tasks

## Functions 
```{r}
#sums NA values then uses the apply family of functions to obtain NA values per column
AppSumNa = function(x){
  ty = is.na(x)
  yt= function(y){
    sum(ty)
  } 
  yy = apply(x, 2, yt)
  return(yy)
}
```

## Importing and Inspecting datasets{#S1}

```{r Importing datasets}
# Loading information household dataset
inform = read.csv("informations_households.csv")
# Loading daily consumption dataset
daily = read.csv("daily_dataset.csv")
# Loading daily weather dataset
weather = read.csv("weather_daily_darksky.csv")
```

```{r Selecting important columns from weather dataset}
# Removing columns that are not required from the weather dataset
weather = weather[,c(1,2,3,4,6,7,8,12,13,14,18,19,21,22,23,27)]
```


```{r}
# Changing weather to date format for the join between datasets
weather$time = as.Date(weather$time)
```

```{r}
# Joining daily dataset using local id column
inform_daily = inner_join(daily,inform,by="LCLid")
# Changing the day column of the inform_daily dataset to enable the join between datasets
inform_daily$day =  as.Date(inform_daily$day)
# Joining weather data to the dataset
london_smart_meter = inner_join(inform_daily,weather,by=c("day"="time"))
# Removing a ACORN data quality issue
london_smart_meter<- london_smart_meter %>% 
  filter(Acorn_grouped !="ACORN-")
```


```{r}
# Checking the sum of NA's in the data
AppSumNa(london_smart_meter)
# Dropping NA's in question
noNa_london_smart_meter= na.omit(london_smart_meter)
```



```{r}
# Removing two columns that are not needed from the weather dataset
noNa_london_smart_meter <- noNa_london_smart_meter[,-c(15,18)]
```


```{r}

# Checking the percentage of smart meter users that belong to different ACORN's
noNa_london_smart_meter %>% 
  count(Acorn_grouped) %>% 
  mutate(total=nrow(noNa_london_smart_meter)) %>% 
  summarise(Acorn_grouped,n, n/total)

# Removing the data quality from this intermediary set 
inform <- inform %>% 
  filter(Acorn_grouped!="ACORN-")

#Checking percentage of Dataset to determine what the sampling probability should be
inform %>% 
  count(Acorn_grouped) %>% 
  mutate(total=nrow(inform)) %>% 
  summarise(Acorn_grouped,n,n/total)
```

```{r}
# Finding out which files must be bound together to get apply clustering 
files = noNa_london_smart_meter %>% 
  group_by(file) %>% 
  count(file)
```


```{r}
#Exploratory Data Analysis
hist(noNa_london_smart_meter$temperatureMax)
hist(noNa_london_smart_meter$windSpeed)
```

```{r}
# This graph will demonstrate the need for dimensionality reduction and possibly a clustering method that can cut through noise
plot(noNa_london_smart_meter$energy_max,noNa_london_smart_meter$temperatureMax)
```

```{r}
# Some data cleaning must be performed to check values like min temperature to make sure there are invalid
# Dimensionality reduction must be considered at this stage before covering any EDA
# Pre-processing strategy must be carried out

# Sampling must be performed to cut a sample out of the 3000000 observations in the dataset

# samp <- sampling::strata(noNa_london_smart_meter,method = "srswor",size = 100000)

# london_smartM = noNa_london_smart_meter 

# hclust_london_smartM <- hclust(london_smartM,method = "complete")




```

